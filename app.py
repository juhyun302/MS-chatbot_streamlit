import streamlit as st
import os
import json 
from openai import AzureOpenAI
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (Azure í‚¤/ì—”ë“œí¬ì¸íŠ¸ëŠ” .env íŒŒì¼ì— ìˆì–´ì•¼ í•¨)
load_dotenv()

st.set_page_config(
    page_title="F1 DTS íë ˆì´í„° ì±—ë´‡",
    page_icon="ğŸï¸",
    layout="wide",
)
st.title("ğŸï¸ F1 ë³¸ëŠ¥ì˜ ì§ˆì£¼ ì…ë¬¸ ê°€ì´ë“œ")
st.caption("ìˆ˜ì—…ì—ì„œ ë°°ìš´ Function Calling ê¸°ìˆ ì„ í™œìš©í•©ë‹ˆë‹¤. (ê²€ìƒ‰ ëŒ€ìƒ: DTS ë¬¸ì„œ)")
st.divider()

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • 
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# -----------------------------------------------------
# â­ Tool-Use (Function Calling) ì •ì˜ ì˜ì—­ â­
# -----------------------------------------------------

# 1. Tool ì—­í• ì„ í•  í•¨ìˆ˜ ì •ì˜ (DTS ë¬¸ì„œ ê²€ìƒ‰ ë”ë¯¸ ë°ì´í„° ì‚¬ìš©)
def search_dts_knowledge(query: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ 'F1 ë³¸ëŠ¥ì˜ ì§ˆì£¼'ì˜ ì‹œì¦Œ/ì—í”¼ì†Œë“œë³„ í•µì‹¬ ë‚´ìš©, ë“œë¼ì´ë²„ ì´ì•¼ê¸°, íŒ€ ì „ëµ ë¬¸ì„œë¥¼ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ì‹¤ì œ RAG ì‹œìŠ¤í…œì´ ë¬¸ì„œì—ì„œ ì°¾ì€ ë‚´ìš©ì„ ë°˜í™˜í•œë‹¤ê³  ê°€ì •
    if "ë‹¤ë‹ˆì—˜ ë¦¬ì¹´ë¥´ë„" in query or "ë¥´ë…¸" in query:
        return "ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼: ë‹¤ë‹ˆì—˜ ë¦¬ì¹´ë¥´ë„ì˜ ë ˆë“œë¶ˆ ì´ì  ê²°ì •ê³¼ ë¥´ë…¸ì—ì„œì˜ ìƒˆë¡œìš´ ì‹œì‘ì€ 'ë³¸ëŠ¥ì˜ ì§ˆì£¼' S1ì˜ ì£¼ìš” ì£¼ì œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ê·¸ì˜ ì´ì  ë°°ê²½ê³¼ ì‹¬ê²½ ë³€í™”ê°€ ì˜ ë‹¤ë¤„ì§‘ë‹ˆë‹¤."
    elif "í•˜ìŠ¤" in query or "ìŠˆíƒ€ì´ë„ˆ" in query:
        return "ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼: í•˜ìŠ¤ íŒ€ì€ ì˜ˆì‚°ê³¼ ì„±ëŠ¥ ë¬¸ì œë¡œ ì–´ë ¤ì›€ì„ ê²ªì—ˆìœ¼ë©°, íŒ€ ë³´ìŠ¤ êµ°í„° ìŠˆíƒ€ì´ë„ˆì˜ ê±°ì¹¨ì—†ëŠ” ì–´ë¡ê³¼ ë¦¬ë”ì‹­ì´ S3ì™€ S4ì— ê±¸ì³ ì§‘ì¤‘ ì¡°ëª…ë©ë‹ˆë‹¤."
    elif "í•´ë°€í„´" in query:
        return "ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼: ë£¨ì´ìŠ¤ í•´ë°€í„´ì˜ ì¸ì¢…ì°¨ë³„ ë°˜ëŒ€ í™œë™ê³¼ ì‚¬íšŒì  ë©”ì‹œì§€ ì „ë‹¬ì— ëŒ€í•œ ë‚´ìš©ì´ S3ì—ì„œ ìƒì„¸íˆ ë‹¤ë¤„ì§‘ë‹ˆë‹¤. ë©”ë¥´ì„¸ë°ìŠ¤ íŒ€ì˜ ì••ë„ì ì¸ ì„±ê³¼ë„ í•¨ê»˜ ë‚˜ì˜µë‹ˆë‹¤."
    else:
        return f"ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼: '{query}'ì— ëŒ€í•œ 'ë³¸ëŠ¥ì˜ ì§ˆì£¼' ê´€ë ¨ ìš”ì•½ ì •ë³´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì´ëŠ” F1ì˜ ë³µì¡í•œ ë°°ê²½ ì§€ì‹ì„ ì‰½ê²Œ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤."

# 2. LLMì—ê²Œ ì „ë‹¬í•  Tool Schema ì •ì˜
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "search_dts_knowledge",
            "description": "F1 ë³¸ëŠ¥ì˜ ì§ˆì£¼(DTS) ë‹¤íë©˜í„°ë¦¬ ë‚´ìš©, ë“œë¼ì´ë²„ ë¹„í•˜ì¸ë“œ, íŒ€ ì „ëµ ë“± ë°°ê²½ ì§€ì‹ ê²€ìƒ‰ì´ í•„ìš”í•  ë•Œ ë°˜ë“œì‹œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "DTS ë¬¸ì„œì—ì„œ ì°¾ì„ í•µì‹¬ í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸ (ì˜ˆ: 'êµ°í„° ìŠˆíƒ€ì´ë„ˆì˜ ìœ ëª…í•œ ëŒ€ì‚¬', 'ë¦¬ì¹´ë¥´ë„ì˜ ì´ì  ì´ìœ ')."
                    }
                },
                "required": ["query"],
            },
        }
    }
]

# 3. í•¨ìˆ˜ ì´ë¦„ê³¼ ì‹¤ì œ í•¨ìˆ˜ë¥¼ ì—°ê²°
AVAILABLE_FUNCTIONS = {
    "search_dts_knowledge": search_dts_knowledge,
}
# -----------------------------------------------------

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    temperature = st.slider("ì°½ì˜ì„± (temperature)", 0.0, 1.0, 0.7, 0.1)
    system_prompt = st.text_area(
        "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
        "ë„ˆëŠ” 'F1 ë³¸ëŠ¥ì˜ ì§ˆì£¼' ì „ë¬¸ íë ˆì´í„° ì±—ë´‡ì´ì•¼. F1 ì…ë¬¸ì ë¯¼ìˆ˜ë¥¼ ë•ëŠ” ê²ƒì´ ëª©í‘œì´ë©°, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ **ë°˜ë“œì‹œ** Toolì„ ì‚¬ìš©í•´ì„œ ê´€ë ¨ DTS ë¬¸ì„œì˜ ë‚´ìš©ì„ ì°¾ì•„ì˜¨ ë’¤, ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **í¥ë¯¸ë¡­ê³  ì‰½ê²Œ** ë‹µë³€í•´ì¤˜ì•¼ í•´.",
        height=150,
    )
    st.markdown("---")
    st.markdown("**Made with ğŸ’™ Streamlit + Azure OpenAI**")

# ëŒ€í™”ê¸°ë¡(Session State) ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("DTSì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"):
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # (2) AI ì‘ë‹µ ìƒì„± (Function Calling ë£¨í”„ ì‹œì‘)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # 1ì°¨ í˜¸ì¶œì„ ìœ„í•œ ë©”ì‹œì§€ êµ¬ì„±
        messages_for_api = [
            {"role": "system", "content": system_prompt}
        ] + st.session_state.messages
        
        # â­ 1ì°¨ í˜¸ì¶œ: Tool í˜¸ì¶œì„ ê°•ì œ (í…ŒìŠ¤íŠ¸ ëª©ì )
        # ì´ ì„¤ì •ì€ í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí•˜ë©´ "auto"ë¡œ ë°”ê¾¸ê³  í”„ë¡¬í”„íŠ¸ë¥¼ ê°•í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        response = client.chat.completions.create(
            model="gpt-4o-mini", # <<<< â­ ë°°í¬ëª…ìœ¼ë¡œ ìˆ˜ì • í•„ìˆ˜!
            messages=messages_for_api,
            tools=TOOLS,             
            tool_choice={"type": "function", "function": {"name": "search_dts_knowledge"}}, 
            temperature=temperature,
        )

        assistant_message = response.choices[0].message
        
        # â­ Tool í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš° (ìš°ë¦¬ê°€ ê°•ì œí–ˆìœ¼ë¯€ë¡œ ì´ ì¡°ê±´ë¬¸ì´ Trueì—¬ì•¼ í•¨)
        if assistant_message.tool_calls and len(assistant_message.tool_calls) > 0:
            # ì±—ë´‡ì´ ìƒê°í•˜ëŠ” ê³¼ì • ë³´ì—¬ì£¼ê¸°
            message_placeholder.markdown("ğŸ§ **DTS ë¬¸ì„œ**ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤... ğŸ”")
            
            # Tool í˜¸ì¶œ ìš”ì²­ ì²˜ë¦¬ ë£¨í”„
            for tool_call in assistant_message.tool_calls:
                function_name = tool_call.function.name
                
                if function_name in AVAILABLE_FUNCTIONS:
                    function_to_call = AVAILABLE_FUNCTIONS[function_name]
                    # argumentsê°€ JSON ë¬¸ìì—´ì¸ì§€ í™•ì¸ í›„ íŒŒì‹±
                    try:
                        function_args = json.loads(tool_call.function.arguments)
                    except json.JSONDecodeError:
                        st.error("ì˜¤ë¥˜: LLMì´ ë°˜í™˜í•œ í•¨ìˆ˜ ì¸ìˆ˜ê°€ ìœ íš¨í•œ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")
                        continue
                        
                    # í•¨ìˆ˜ ì‹¤í–‰ (DTS ë¬¸ì„œ ê²€ìƒ‰ ë”ë¯¸ ì‹¤í–‰)
                    function_response = function_to_call(
                        query=function_args.get("query", "")
                    )

                    # Tool ì‹¤í–‰ ìš”ì²­ê³¼ ê²°ê³¼ë¥¼ messages_for_apiì— ì¶”ê°€
                    messages_for_api.append(assistant_message) # 1ì°¨ ì‘ë‹µ (Tool ìš”ì²­)
                    messages_for_api.append(
                        {
                            "tool_call_id": tool_call.id,
                            "role": "tool",
                            "name": function_name,
                            "content": function_response, # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼
                        }
                    )
                else:
                    st.error(f"ì˜¤ë¥˜: ì•Œ ìˆ˜ ì—†ëŠ” í•¨ìˆ˜ í˜¸ì¶œ {function_name}")
            
            # â­ 2ì°¨ í˜¸ì¶œ: Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ LLMì—ê²Œ ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
            message_placeholder.markdown("âœ¨ **DTS ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ!** ë¯¼ìˆ˜ê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë‹µë³€ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... ğŸ¤–")

            try:
                # 2ì°¨ í˜¸ì¶œ ì‹œë„
                response = client.chat.completions.create(
                    model="gpt-4o-mini", # <<<< â­ ë°°í¬ëª…ìœ¼ë¡œ ìˆ˜ì • í•„ìˆ˜!
                    messages=messages_for_api, # Tool ì‹¤í–‰ ê²°ê³¼ê°€ ì¶”ê°€ëœ ë©”ì‹œì§€ ì „ë‹¬
                    temperature=temperature,
                )
    
                # ì‘ë‹µì´ ì„±ê³µì ìœ¼ë¡œ ì™”ì„ ë•Œ
                assistant_reply = response.choices[0].message.content
    
            except Exception as e:
                # API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜(Error)ê°€ ë°œìƒí•˜ë©´ ì´ ë¶€ë¶„ì´ ì‹¤í–‰ë¨
                st.error(f"ğŸš¨ 2ì°¨ API í˜¸ì¶œ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
                assistant_reply = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì„œë²„ ë¬¸ì œë¡œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì˜¤ë¥˜ ì½”ë“œ: {str(e)[:50]}...)"
    
            # ìµœì¢… ë‹µë³€ í™”ë©´ì— ì¶œë ¥ & ì €ì¥
            message_placeholder.markdown(assistant_reply)
            st.session_state.messages.append({"role": "assistant", "content": assistant_reply})

