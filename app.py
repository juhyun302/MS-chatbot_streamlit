import streamlit as st
import os
import json # â­ json ëª¨ë“ˆ ì¶”ê°€
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (Azure í‚¤/ì—”ë“œí¬ì¸íŠ¸ëŠ” .env íŒŒì¼ì— ìˆì–´ì•¼ í•¨)
load_dotenv()

st.set_page_config(
    page_title="F1 ì±—ë´‡ ê¸°íš í…ŒìŠ¤íŠ¸",
    page_icon="ğŸï¸",
    layout="wide",
)
st.title("ğŸï¸ F1 ì‹¤ì‹œê°„ ì •ë³´ íë ˆì´í„° (Tool-Use í…ŒìŠ¤íŠ¸)")
st.caption("LLMì´ ì–¸ì œ ê²€ìƒ‰(Tool)ì„ í˜¸ì¶œí•˜ëŠ”ì§€ í™•ì¸í•´ ë´…ì‹œë‹¤.")
st.divider()

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ í™•ì¸ í•„ìˆ˜!)
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# -----------------------------------------------------
# â­ Tool-Use (Function Calling) ì •ì˜ ì˜ì—­ â­
# -----------------------------------------------------

# 1. Tool ì—­í• ì„ í•  í•¨ìˆ˜ ì •ì˜ (ì‹¤ì œ ì›¹ ê²€ìƒ‰ ëŒ€ì‹  ë”ë¯¸ ë°ì´í„° ì‚¬ìš©)
def search_web(query: str) -> str:
    """
    ìµœì‹  F1 ì •ë³´, ë ˆì´ìŠ¤ ê²°ê³¼, ë“œë¼ì´ë²„ ìˆœìœ„ ë“± ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    # ë”ë¯¸ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜
    if "ìŠ¤í˜ì¸ GP ìš°ìŠ¹" in query or "ìŠ¤í˜ì¸ ìš°ìŠ¹" in query:
        return "ì›¹ ê²€ìƒ‰ ê²°ê³¼: 2024ë…„ ìŠ¤í˜ì¸ GPì—ì„œëŠ” Red Bullì˜ Max Verstappen ì„ ìˆ˜ê°€ ìš°ìŠ¹í–ˆìŠµë‹ˆë‹¤."
    elif "2025ë…„ í˜ë¼ë¦¬" in query or "í˜ë¼ë¦¬ ë“œë¼ì´ë²„" in query:
        return "ì›¹ ê²€ìƒ‰ ê²°ê³¼: 2025ë…„ í˜ë¼ë¦¬ ë“œë¼ì´ë²„ ë¼ì¸ì—…ì€ Charles Leclercì™€ Lewis Hamiltonì…ë‹ˆë‹¤. (Hamiltonì€ Mercedesì—ì„œ ì´ì )"
    else:
        # LLMì´ Toolì„ ì‚¬ìš©í–ˆëŠ”ë° ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ ì¼ë°˜ ì‘ë‹µ
        return f"'{query}'ì— ëŒ€í•œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ëŠ” '2024ë…„ F1 ì‹œì¦Œì´ ì§„í–‰ ì¤‘ì´ë©°, 3ì£¼ ë’¤ ì˜êµ­ GPê°€ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.' ì™€ ê°™ìŠµë‹ˆë‹¤."

# 2. LLMì—ê²Œ ì „ë‹¬í•  Tool Schema ì •ì˜
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "search_web",
            "description": "ìµœì‹  F1 ì •ë³´, **íŠ¹íˆ 2024ë…„ ì´í›„ì˜ ë ˆì´ìŠ¤ ê²°ê³¼, ë“œë¼ì´ë²„ ì´ì  ë‰´ìŠ¤, íŒ€ ìˆœìœ„ ë³€ë™ ë“±** ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•  ë•Œ **ë°˜ë“œì‹œ** ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "ì›¹ ê²€ìƒ‰ì— ì‚¬ìš©í•  ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ (ì˜ˆ: '2024ë…„ ìŠ¤í˜ì¸ ê·¸ë‘í”„ë¦¬ ìš°ìŠ¹ì')."
                    }
                },
                "required": ["query"],
            },
        }
    }
]

# 3. í•¨ìˆ˜ ì´ë¦„ê³¼ ì‹¤ì œ í•¨ìˆ˜ë¥¼ ì—°ê²°
AVAILABLE_FUNCTIONS = {
    "search_web": search_web,
}
# -----------------------------------------------------

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    temperature = st.slider("ì°½ì˜ì„± (temperature)", 0.0, 1.0, 0.7, 0.1)
    system_prompt = st.text_area(
        "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
        "ë„ˆëŠ” F1 ì „ë¬¸ ë¶„ì„ê°€ ì±—ë´‡ì´ì•¼. F1 ê´€ë ¨ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜. ë‹µë³€ ì‹œ í•­ìƒ LLMì˜ ìì²´ ì§€ì‹ê³¼ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ë ¤ê³  ë…¸ë ¥í•´.",
        height=150,
    )
    st.markdown("---")
    st.markdown("**Made with ğŸ’™ Streamlit + Azure OpenAI**")

# ëŒ€í™”ê¸°ë¡(Session State) ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("F1ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"):
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥ (ê¸°ì¡´ê³¼ ë™ì¼)
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # (2) AI ì‘ë‹µ ìƒì„± ì‹œì‘
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # â­ 1. LLMì˜ íŒë‹¨ ì—†ì´, ì½”ë“œ ë ˆë²¨ì—ì„œ ë¬´ì¡°ê±´ ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ
        #    ì‚¬ìš©ìì˜ ì§ˆë¬¸(prompt)ì„ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì‚¬ìš©
        message_placeholder.markdown("ğŸ§ ìµœì‹  F1 ì •ë³´ë¥¼ ê²€ìƒ‰ ì¤‘... ğŸ”")
        function_response = search_web(query=prompt) # search_web í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ
        
        # â­ 2. 2ì°¨ í˜¸ì¶œì„ ìœ„í•œ ë©”ì‹œì§€ êµ¬ì„±: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ëŒ€í™” ê¸°ë¡ + ê²€ìƒ‰ ê²°ê³¼
        messages_for_api = [
            {"role": "system", "content": system_prompt},
            *st.session_state.messages, # ê¸°ì¡´ ì‚¬ìš©ì/AI ëŒ€í™” ê¸°ë¡ ëª¨ë‘ í¬í•¨
            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì—ê²Œ ì§ì ‘ ì „ë‹¬
            {"role": "user", "content": f"ê²€ìƒ‰ ê²°ê³¼ê°€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: '{function_response}' ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ì§ˆë¬¸ì¸ '{prompt}'ì— ë‹µë³€í•˜ì„¸ìš”."}
        ]

        # â­ 3. ë‹¨ í•œ ë²ˆë§Œ API í˜¸ì¶œí•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
        message_placeholder.markdown("âœ¨ ê²€ìƒ‰ ì™„ë£Œ! ë‹µë³€ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... ğŸ¤–")
        response = client.chat.completions.create(
            model="gpt-4o-mini", # <<<< â­ ë°°í¬ëª…ìœ¼ë¡œ ìˆ˜ì • í•„ìˆ˜!
            messages=messages_for_api, # ê²€ìƒ‰ ê²°ê³¼ê°€ í¬í•¨ëœ ë©”ì‹œì§€ ì „ë‹¬
            temperature=temperature,
        )
        assistant_reply = response.choices[0].message.content
            
        # ìµœì¢… ë‹µë³€ í™”ë©´ì— ì¶œë ¥ & ì €ì¥ (ê¸°ì¡´ê³¼ ë™ì¼)
        message_placeholder.markdown(assistant_reply)
        st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
