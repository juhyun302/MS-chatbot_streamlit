import streamlit as st
import os
import json # â­ json ëª¨ë“ˆ ì¶”ê°€
from openai import AzureOpenAI
from dotenv import load_dotenv

# 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (Azure í‚¤/ì—”ë“œí¬ì¸íŠ¸ëŠ” .env íŒŒì¼ì— ìˆì–´ì•¼ í•¨)
load_dotenv()

st.set_page_config(
    page_title="F1 ì±—ë´‡ ê¸°íš í…ŒìŠ¤íŠ¸",
    page_icon="ğŸï¸",
    layout="wide",
)
st.title("ğŸï¸ F1 ì‹¤ì‹œê°„ ì •ë³´ íë ˆì´í„° (Tool-Use í…ŒìŠ¤íŠ¸)")
st.caption("LLMì´ ì–¸ì œ ê²€ìƒ‰(Tool)ì„ í˜¸ì¶œí•˜ëŠ”ì§€ í™•ì¸í•´ ë´…ì‹œë‹¤.")
st.divider()

# 2. Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ í™•ì¸ í•„ìˆ˜!)
client = AzureOpenAI(
    api_key=os.getenv("AZURE_OAI_KEY"),
    api_version="2024-05-01-preview",
    azure_endpoint=os.getenv("AZURE_OAI_ENDPOINT")
)

# -----------------------------------------------------
# â­ Tool-Use (Function Calling) ì •ì˜ ì˜ì—­ â­
# -----------------------------------------------------

# 1. Tool ì—­í• ì„ í•  í•¨ìˆ˜ ì •ì˜ (ì‹¤ì œ ì›¹ ê²€ìƒ‰ ëŒ€ì‹  ë”ë¯¸ ë°ì´í„° ì‚¬ìš©)
def search_web(query: str) -> str:
    """
    ìµœì‹  F1 ì •ë³´, ë ˆì´ìŠ¤ ê²°ê³¼, ë“œë¼ì´ë²„ ìˆœìœ„ ë“± ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    # ë”ë¯¸ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜
    if "ìŠ¤í˜ì¸ GP ìš°ìŠ¹" in query or "ìŠ¤í˜ì¸ ìš°ìŠ¹" in query:
        return "ì›¹ ê²€ìƒ‰ ê²°ê³¼: 2024ë…„ ìŠ¤í˜ì¸ GPì—ì„œëŠ” Red Bullì˜ Max Verstappen ì„ ìˆ˜ê°€ ìš°ìŠ¹í–ˆìŠµë‹ˆë‹¤."
    elif "2025ë…„ í˜ë¼ë¦¬" in query or "í˜ë¼ë¦¬ ë“œë¼ì´ë²„" in query:
        return "ì›¹ ê²€ìƒ‰ ê²°ê³¼: 2025ë…„ í˜ë¼ë¦¬ ë“œë¼ì´ë²„ ë¼ì¸ì—…ì€ Charles Leclercì™€ Lewis Hamiltonì…ë‹ˆë‹¤. (Hamiltonì€ Mercedesì—ì„œ ì´ì )"
    else:
        # LLMì´ Toolì„ ì‚¬ìš©í–ˆëŠ”ë° ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ ì¼ë°˜ ì‘ë‹µ
        return f"'{query}'ì— ëŒ€í•œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ëŠ” '2024ë…„ F1 ì‹œì¦Œì´ ì§„í–‰ ì¤‘ì´ë©°, 3ì£¼ ë’¤ ì˜êµ­ GPê°€ ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.' ì™€ ê°™ìŠµë‹ˆë‹¤."

# 2. LLMì—ê²Œ ì „ë‹¬í•  Tool Schema ì •ì˜
TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "search_web",
            "description": "ìµœì‹  F1 ì •ë³´, ë ˆì´ìŠ¤ ê²°ê³¼, ë“œë¼ì´ë²„ ìˆœìœ„, íŒ€ ë‰´ìŠ¤ ë“± ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "ì›¹ ê²€ìƒ‰ì— ì‚¬ìš©í•  ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ (ì˜ˆ: '2024ë…„ ìŠ¤í˜ì¸ ê·¸ë‘í”„ë¦¬ ìš°ìŠ¹ì')."
                    }
                },
                "required": ["query"],
            },
        }
    }
]

# 3. í•¨ìˆ˜ ì´ë¦„ê³¼ ì‹¤ì œ í•¨ìˆ˜ë¥¼ ì—°ê²°
AVAILABLE_FUNCTIONS = {
    "search_web": search_web,
}
# -----------------------------------------------------

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    temperature = st.slider("ì°½ì˜ì„± (temperature)", 0.0, 1.0, 0.7, 0.1)
    system_prompt = st.text_area(
        "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸",
        "ë„ˆëŠ” F1 ì „ë¬¸ ë¶„ì„ê°€ ì±—ë´‡ì´ì•¼. F1 ê´€ë ¨ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì¤˜. ë‹µë³€ ì‹œ í•­ìƒ LLMì˜ ìì²´ ì§€ì‹ê³¼ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•˜ë ¤ê³  ë…¸ë ¥í•´.",
        height=150,
    )
    st.markdown("---")
    st.markdown("**Made with ğŸ’™ Streamlit + Azure OpenAI**")

# ëŒ€í™”ê¸°ë¡(Session State) ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

# í™”ë©´ì— ê¸°ì¡´ ëŒ€í™” ë‚´ìš© ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
if prompt := st.chat_input("F1ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"):
    # (1) ì‚¬ìš©ì ë©”ì‹œì§€ í™”ë©´ì— í‘œì‹œ & ì €ì¥
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # (2) AI ì‘ë‹µ ìƒì„± (Function Calling ë£¨í”„ ì‹œì‘)
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # 1ì°¨ í˜¸ì¶œì„ ìœ„í•œ ë©”ì‹œì§€ êµ¬ì„±
        messages_for_api = [
            {"role": "system", "content": system_prompt}
        ] + st.session_state.messages
        
        # â­ 1ì°¨ í˜¸ì¶œ: LLMì´ Tool í˜¸ì¶œì„ í• ì§€ íŒë‹¨
        response = client.chat.completions.create(
            model="gpt-4o-mini", # <<<< â­ ë°°í¬ëª…ìœ¼ë¡œ ìˆ˜ì • í•„ìˆ˜!
            messages=messages_for_api,
            tools=TOOLS,             
            tool_choice="auto",      
            temperature=temperature,
        )

        assistant_message = response.choices[0].message
        
        # â­ Tool í˜¸ì¶œì´ í•„ìš”í•œ ê²½ìš°
        if assistant_message.tool_calls:
            # ì±—ë´‡ì´ ìƒê°í•˜ëŠ” ê³¼ì • ë³´ì—¬ì£¼ê¸°
            message_placeholder.markdown("ğŸ§ **ì •ë³´ ë¶€ì¡±!** ìµœì‹  F1 ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ìˆìŠµë‹ˆë‹¤... ğŸ”")
            
            # Tool í˜¸ì¶œ ìš”ì²­ ì²˜ë¦¬ ë£¨í”„
            for tool_call in assistant_message.tool_calls:
                function_name = tool_call.function.name
                
                # ì •ì˜ëœ í•¨ìˆ˜ì¸ì§€ í™•ì¸í•˜ê³  ì‹¤í–‰ ì¤€ë¹„
                if function_name in AVAILABLE_FUNCTIONS:
                    function_to_call = AVAILABLE_FUNCTIONS[function_name]
                    function_args = json.loads(tool_call.function.arguments)
                    
                    # í•¨ìˆ˜ ì‹¤í–‰ (ë”ë¯¸ ì›¹ ê²€ìƒ‰ ì‹¤í–‰)
                    function_response = function_to_call(
                        query=function_args.get("query", "")
                    )

                    # Tool ì‹¤í–‰ ìš”ì²­ê³¼ ê²°ê³¼ë¥¼ messages_for_apiì— ì¶”ê°€
                    messages_for_api.append(assistant_message) # 1ì°¨ ì‘ë‹µ (Tool ìš”ì²­)
                    messages_for_api.append(
                        {
                            "tool_call_id": tool_call.id,
                            "role": "tool",
                            "name": function_name,
                            "content": function_response, # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼ (ì›¹ ê²€ìƒ‰ ê²°ê³¼)
                        }
                    )
                else:
                    # ì •ì˜ë˜ì§€ ì•Šì€ í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ì˜¤ë¥˜ ì²˜ë¦¬
                    st.error(f"ì˜¤ë¥˜: ì•Œ ìˆ˜ ì—†ëŠ” í•¨ìˆ˜ í˜¸ì¶œ {function_name}")
            
            # â­ 2ì°¨ í˜¸ì¶œ: Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ LLMì—ê²Œ ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
            message_placeholder.markdown("âœ¨ **ê²€ìƒ‰ ì™„ë£Œ!** ìµœì‹  ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”... ğŸ¤–")
            response = client.chat.completions.create(
                model="gpt-4o-mini", # <<<< â­ ë°°í¬ëª…ìœ¼ë¡œ ìˆ˜ì • í•„ìˆ˜!
                messages=messages_for_api, # Tool ì‹¤í–‰ ê²°ê³¼ê°€ ì¶”ê°€ëœ ë©”ì‹œì§€ ì „ë‹¬
                temperature=temperature,
            )
            assistant_reply = response.choices[0].message.content
            
        else:
            # Tool í˜¸ì¶œì´ í•„ìš” ì—†ëŠ” ì¼ë°˜ ë‹µë³€ (LLM ìì²´ ì§€ì‹)
            assistant_reply = assistant_message.content

        # ìµœì¢… ë‹µë³€ í™”ë©´ì— ì¶œë ¥ & ì €ì¥
        message_placeholder.markdown(assistant_reply)
        st.session_state.messages.append({"role": "assistant", "content": assistant_reply})
